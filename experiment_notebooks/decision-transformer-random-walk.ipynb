{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:58:31.266941Z",
     "start_time": "2024-05-08T08:58:31.158219Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "from envs.random_walk import RandomWalkEnv\n",
    "# from algorithms.sequence_models.old_decision_transformer.decision_transformer.decision_transformer import DecisionTransformer\n",
    "from algorithms.sequence_models.decision_transformer.decision_transformer import DecisionTransformer\n",
    "from algorithms.sequence_models.decision_transformer.evaluate import evaluate_on_env\n",
    "from algorithms.sequence_models.old_decision_transformer.decision_transformer.trainer import DecisionTransformerTrainer\n",
    "from data.random_walk_dataset import RandomWalkDataset\n",
    "from data.trajectory import LimitedContextWrapper\n",
    "from settings import LOG_DIR\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:49:17.710694Z",
     "start_time": "2024-05-08T08:49:14.858471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rtg_target = 8\n",
    "\n",
    "max_eval_ep_len = 20      # max len of one evaluation episode\n",
    "num_eval_ep = 10          # num of evaluation episodes per iteration\n",
    "\n",
    "batch_size = 64             # training batch size\n",
    "lr = 1e-3                   # learning rate\n",
    "wt_decay = 1e-4             # weight decay\n",
    "warmup_steps = 10000        # warmup steps for lr scheduler\n",
    "\n",
    "# total updates = max_train_iters x num_updates_per_iter\n",
    "max_train_iters = 200\n",
    "num_updates_per_iter = 100\n",
    "\n",
    "context_len = 20        # K in decision transformer\n",
    "n_blocks = 3            # num of transformer blocks\n",
    "embed_dim = 128         # embedding (hidden) dim of transformer\n",
    "n_heads = 1             # num of transformer heads\n",
    "dropout_p = 0.1         # dropout probability\n",
    "\n",
    "env = RandomWalkEnv()\n",
    "traj_dataset = RandomWalkDataset(n_trajectories=10000)"
   ],
   "id": "ae075e310b94044a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "episode_max_length: 8\n",
      "reward_scale: 9\n",
      "return min=-18, max=9 mean=-3.3927041554118578\n",
      "state_mean: [0.50380617 0.20280483 0.09613653 0.17100488 0.02624758 0.        ]\n",
      "state_std: [0.49998551 0.40208834 0.29477839 0.37651323 0.15987071 0.        ]\n",
      "gamma: 1\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:49:23.741981Z",
     "start_time": "2024-05-08T08:49:23.685642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Logger:\n",
    "\tdef __init__(self, name):\n",
    "\t\tself.name = name\n",
    "\t\tself.start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\t\tself.best_score = -np.inf\n",
    "\t\tself.iters = 0\n",
    "\t\tself.num_updates_per_iter = 0\n",
    "\t\tself.previous_csv_extra_keys = None\n",
    "\t\t\n",
    "\t\tself.log_dir = os.path.join(LOG_DIR, \"dt_runs\")\n",
    "\t\t\n",
    "\t\tself.save_model_path = \"\"\n",
    "\t\tself.save_best_model_path = \"\"\n",
    "\n",
    "\t\tif not os.path.exists(self.log_dir):\n",
    "\t\t\tos.makedirs(self.log_dir)\n",
    "\t\t\n",
    "\t\tself.csv_writer = None\n",
    "\t\tself.pbar = None\t\t\n",
    "\t\tself.is_started = False\n",
    "\n",
    "\tdef start(self, iterations, update_per_iter):\t\t\n",
    "\t\tself.start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\t\tself.best_score = -np.inf\n",
    "\t\tself.iters = 0\n",
    "\t\tself.num_updates_per_iter = update_per_iter\n",
    "\t\tself.previous_csv_extra_keys = None\n",
    "\t\t\n",
    "\t\tprefix = \"dt_\"\n",
    "\t\tstart_time_str = self.start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\t\tsave_model_name = prefix + self.name + \"_model_\" + start_time_str + \".pt\"\n",
    "\t\tself.save_model_path = os.path.join(self.log_dir, save_model_name)\n",
    "\t\tself.save_best_model_path = self.save_model_path[:-3] + \"_best.pt\"\n",
    "\t\tlog_csv_name = prefix + \"_log_\" + start_time_str + \".csv\"\n",
    "\t\tlog_csv_path = os.path.join(self.log_dir, log_csv_name)\n",
    "\t\tself.csv_writer = csv.writer(open(log_csv_path, 'a', 1))\n",
    "\t\t\n",
    "\t\tself.pbar = None\t\t\n",
    "\t\tself.is_started = True\n",
    "\t\tself.pbar = tqdm(total=iterations)\n",
    "\n",
    "\tdef finish(self):\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\tprint(\"finished training!\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\tend_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\t\ttime_elapsed = str(end_time - self.start_time)\n",
    "\t\tend_time_str = end_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\t\t\n",
    "\t\tstart_time_str = self.start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "\t\tprint(\"started training at: \" + start_time_str)\n",
    "\t\tprint(\"finished training at: \" + end_time_str)\n",
    "\t\tprint(\"total training time: \" + time_elapsed)\n",
    "\t\tprint(\"best score: \" + format(self.best_score, \".5f\"))\n",
    "\t\tprint(\"saved max d4rl score model at: \" + self.save_best_model_path)\n",
    "\t\tprint(\"saved last updated model at: \" + self.save_model_path)\n",
    "\t\tprint(\"=\" * 60)\n",
    "\n",
    "\t\tself.is_started = False\n",
    "\t\tself.csv_writer.close()\n",
    "\n",
    "\t# todo later make it generic so that we can log whatever\n",
    "\tdef log(self, model, mean_action_loss, eval_avg_reward, important=set(), **kwargs):\t\t\n",
    "\t\tif not self.is_started:\n",
    "\t\t\traise Exception(\"call .start() first\")\n",
    "\n",
    "\t\tif self.previous_csv_extra_keys is None:\n",
    "\t\t\tself.previous_csv_extra_keys = list(kwargs.keys())\n",
    "\t\t\tcsv_header = ([\"duration\", \"num_updates\", \"action_loss\", \"eval_avg_reward\", \"best_score\", *kwargs.keys()])\n",
    "\t\t\tself.csv_writer.writerow(csv_header)\n",
    "\t\telif set(self.previous_csv_extra_keys) != set(kwargs.keys()):\n",
    "\t\t\traise Exception(f\"expected {set(self.previous_csv_extra_keys)} keys but passed {set(kwargs.keys())}. Maybe call finish?\")\n",
    "\t\t\n",
    "\t\tself.iters += 1\n",
    "\t\ttime_elapsed = str(datetime.datetime.now().replace(microsecond=0) - self.start_time)\n",
    "\t\ttotal_updates = self.iters * self.num_updates_per_iter\n",
    "\t\t\t\t\n",
    "\t\tlog_str = '\\n'.join([\n",
    "\t\t\t\"=\" * 60,\n",
    "\t\t\t\"time elapsed: \" + time_elapsed,\n",
    "\t\t\t\"num of updates: \" + str(total_updates),\n",
    "\t\t\t\"action loss: \" +  format(mean_action_loss, \".5f\"),\n",
    "\t\t\t\"eval avg reward: \" + format(eval_avg_reward, \".5f\"),\n",
    "\t\t\t\"best score: \" + format(self.best_score, \".5f\"),\n",
    "\t\t\t*[key + \" \" + format(value, \".5f\") for key, value in kwargs.items()]\n",
    "\t\t])\n",
    "\n",
    "\t\tlog_data = [time_elapsed, total_updates, mean_action_loss,\n",
    "\t\t\t\t\teval_avg_reward, self.best_score] + [kwargs[key] for key in self.previous_csv_extra_keys]\n",
    "\t\tself.csv_writer.writerow(log_data)\n",
    "\t\tif eval_avg_reward >= self.best_score:\n",
    "\t\t\tprint('achieved average reward: ', eval_avg_reward)\n",
    "\t\t\tprint(\"saving max score model at: \" + self.save_best_model_path)\n",
    "\n",
    "\t\t\ttorch.save(model.state_dict(), self.save_best_model_path)\n",
    "\t\t\tself.best_score = eval_avg_reward\n",
    "\t\n",
    "\t\tprint(\"saving current model at: \" + self.save_model_path)\n",
    "\t\ttorch.save(model.state_dict(), self.save_model_path)\n",
    "\t\t\n",
    "\n",
    "\t\tself.pbar.set_description(' '.join([\n",
    "\t\t\tf'Loss={mean_action_loss}',\n",
    "\t\t\tf'Best_Score={self.best_score}',\n",
    "\t\t\t*[f'{key}={value:.5f}' for key, value in kwargs.items() if key in important]\n",
    "\t\t]))\n",
    "\t\t\n",
    "\t\tself.pbar.update(1)\n",
    "\t\t\n",
    "\t\tprint(log_str)"
   ],
   "id": "7bae31db13ba8b6f",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:56:47.731236Z",
     "start_time": "2024-05-08T08:49:27.700797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_dim = traj_dataset.state_dim()\n",
    "act_dim = traj_dataset.action_dim()\n",
    "\n",
    "dataset = LimitedContextWrapper(traj_dataset, context_len=context_len)\n",
    "logger = Logger(name='random-walk')\n",
    "\n",
    "model = DecisionTransformer(\n",
    "\t\t\tstate_dim=state_dim,\n",
    "\t\t\tact_dim=act_dim,\n",
    "\t\t\tn_blocks=n_blocks,\n",
    "\t\t\th_dim=embed_dim,\n",
    "\t\t\tcontext_len=context_len,\n",
    "\t\t\tn_heads=n_heads,\n",
    "\t\t\tdrop_p=dropout_p,\n",
    "\t\t).to(device)\n",
    "  \n",
    "optimizer = torch.optim.AdamW(\n",
    "\t\t\t\t\tmodel.parameters(), \n",
    "\t\t\t\t\tlr=lr, \n",
    "\t\t\t\t\tweight_decay=wt_decay\n",
    "\t\t\t\t)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "\t\toptimizer,\n",
    "\t\tlambda steps: min((steps+1)/warmup_steps, 1)\n",
    "\t)\n",
    "\n",
    "print(\"number of parameters\", sum(np.prod(param.shape) for param in model.parameters()))\n",
    "\n",
    "\n",
    "traj_data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "data_iter = iter(traj_data_loader)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "logger.start(iterations=max_train_iters, update_per_iter=num_updates_per_iter)\n",
    "\n",
    "for i_train_iter in range(max_train_iters):\n",
    "\n",
    "\tlog_action_losses = []\t\n",
    "\tmodel.train()\n",
    " \n",
    "\tfor _ in range(num_updates_per_iter):\n",
    "\t\ttry:\n",
    "\t\t\ttimesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
    "\t\texcept StopIteration:\n",
    "\t\t\tdata_iter = iter(traj_data_loader)\n",
    "\t\t\ttimesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
    "\n",
    "\t\ttimesteps = timesteps.to(device)\t# B x T\n",
    "\t\tstates = states.to(device)\t\t\t# B x T x state_dim\n",
    "\t\tactions = actions.to(device)\t\t# B x T x act_dim\n",
    "\t\treturns_to_go = returns_to_go.to(device).unsqueeze(dim=-1) # B x T x 1\n",
    "\t\ttraj_mask = traj_mask.to(device)\t# B x T\n",
    "\n",
    "\t\taction_target = torch.clone(actions).detach().to(device)\n",
    "\t\n",
    "\t\tstate_preds, action_preds, return_preds = model.forward(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttimesteps=timesteps,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tstates=states,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tactions=actions,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\treturns_to_go=returns_to_go\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\t\t# only consider non padded elements\n",
    "\t\taction_preds = action_preds.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "\t\taction_target = action_target.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "\n",
    "\t\t# todo maybe MSE is not the best choice for the discrete actions? Do CrossEntropy\n",
    "\t\taction_loss = loss_fn(action_preds, action_target)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\taction_loss.backward()\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "\t\toptimizer.step()\n",
    "\t\tscheduler.step()\n",
    "\n",
    "\t\tlog_action_losses.append(action_loss.detach().cpu().item())\n",
    "\n",
    "\t# todo evaluate on multiple rtg\n",
    "\t# evaluate on env\n",
    "\tresults = evaluate_on_env(model=model, traj_dataset=traj_dataset,\n",
    "\t\t\t\t\t\t\t  device=device,context_len=context_len,\n",
    "\t\t\t\t\t\t\t  env=env, rtg_target=rtg_target,\n",
    "\t\t\t\t\t\t\t  num_eval_ep=num_eval_ep, max_test_ep_len=max_eval_ep_len)\n",
    "\tlogger.log(model=model,\n",
    "\t\t\t   mean_action_loss=np.mean(log_action_losses),\n",
    "\t\t\t   eval_avg_reward=results['eval/avg_reward'],\n",
    "\t\t\t   eval_avg_ep_len=results['eval/avg_ep_len'],\n",
    "\t\t\t   grad_norm=max(torch.norm(param.grad) for param in model.parameters() if param.grad is not None),\n",
    "\t\t\t   lr=optimizer.param_groups[0]['lr'],\n",
    "\t\t\t   important={\"grad_norm\", \"lr\"})\n",
    "\n",
    "logger.finish()"
   ],
   "id": "b4d041583a7eceee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters 1123085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62b429c167d2467ba6e6fb3e67bc166c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "achieved average reward:  -8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:02\n",
      "num of updates: 100\n",
      "action loss: 0.28848\n",
      "eval avg reward: -8.00000\n",
      "best score: -inf\n",
      "eval_avg_ep_len 8.00000\n",
      "grad_norm 0.18789\n",
      "lr 0.00001\n",
      "achieved average reward:  6.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:03\n",
      "num of updates: 200\n",
      "action loss: 0.15953\n",
      "eval avg reward: 6.00000\n",
      "best score: -8.00000\n",
      "eval_avg_ep_len 4.00000\n",
      "grad_norm 0.15029\n",
      "lr 0.00002\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:05\n",
      "num of updates: 300\n",
      "action loss: 0.14736\n",
      "eval avg reward: 5.00000\n",
      "best score: 6.00000\n",
      "eval_avg_ep_len 5.00000\n",
      "grad_norm 0.17542\n",
      "lr 0.00003\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:09\n",
      "num of updates: 400\n",
      "action loss: 0.14480\n",
      "eval avg reward: 8.00000\n",
      "best score: 6.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17720\n",
      "lr 0.00004\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:13\n",
      "num of updates: 500\n",
      "action loss: 0.14272\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18120\n",
      "lr 0.00005\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:17\n",
      "num of updates: 600\n",
      "action loss: 0.14064\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17785\n",
      "lr 0.00006\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:21\n",
      "num of updates: 700\n",
      "action loss: 0.13934\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17133\n",
      "lr 0.00007\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:26\n",
      "num of updates: 800\n",
      "action loss: 0.13848\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14749\n",
      "lr 0.00008\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:30\n",
      "num of updates: 900\n",
      "action loss: 0.13741\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17126\n",
      "lr 0.00009\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:35\n",
      "num of updates: 1000\n",
      "action loss: 0.13728\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20427\n",
      "lr 0.00010\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:39\n",
      "num of updates: 1100\n",
      "action loss: 0.13643\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20302\n",
      "lr 0.00011\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:42\n",
      "num of updates: 1200\n",
      "action loss: 0.13568\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.21029\n",
      "lr 0.00012\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:43\n",
      "num of updates: 1300\n",
      "action loss: 0.13533\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20838\n",
      "lr 0.00013\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:44\n",
      "num of updates: 1400\n",
      "action loss: 0.13456\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18985\n",
      "lr 0.00014\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:44\n",
      "num of updates: 1500\n",
      "action loss: 0.13396\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15090\n",
      "lr 0.00015\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:45\n",
      "num of updates: 1600\n",
      "action loss: 0.13305\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18614\n",
      "lr 0.00016\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:46\n",
      "num of updates: 1700\n",
      "action loss: 0.13254\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18606\n",
      "lr 0.00017\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:47\n",
      "num of updates: 1800\n",
      "action loss: 0.13186\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15329\n",
      "lr 0.00018\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:48\n",
      "num of updates: 1900\n",
      "action loss: 0.13174\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19172\n",
      "lr 0.00019\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:49\n",
      "num of updates: 2000\n",
      "action loss: 0.13072\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15146\n",
      "lr 0.00020\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:50\n",
      "num of updates: 2100\n",
      "action loss: 0.13009\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19140\n",
      "lr 0.00021\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:51\n",
      "num of updates: 2200\n",
      "action loss: 0.12970\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17584\n",
      "lr 0.00022\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:51\n",
      "num of updates: 2300\n",
      "action loss: 0.12897\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.21631\n",
      "lr 0.00023\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:52\n",
      "num of updates: 2400\n",
      "action loss: 0.12870\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15259\n",
      "lr 0.00024\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:53\n",
      "num of updates: 2500\n",
      "action loss: 0.12816\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14506\n",
      "lr 0.00025\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:54\n",
      "num of updates: 2600\n",
      "action loss: 0.12770\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10847\n",
      "lr 0.00026\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:55\n",
      "num of updates: 2700\n",
      "action loss: 0.12770\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20809\n",
      "lr 0.00027\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:56\n",
      "num of updates: 2800\n",
      "action loss: 0.12717\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19700\n",
      "lr 0.00028\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:57\n",
      "num of updates: 2900\n",
      "action loss: 0.12720\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15281\n",
      "lr 0.00029\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:58\n",
      "num of updates: 3000\n",
      "action loss: 0.12696\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18108\n",
      "lr 0.00030\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:58\n",
      "num of updates: 3100\n",
      "action loss: 0.12633\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.23147\n",
      "lr 0.00031\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:59\n",
      "num of updates: 3200\n",
      "action loss: 0.12608\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20291\n",
      "lr 0.00032\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:00\n",
      "num of updates: 3300\n",
      "action loss: 0.12656\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.23783\n",
      "lr 0.00033\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:01\n",
      "num of updates: 3400\n",
      "action loss: 0.12593\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16074\n",
      "lr 0.00034\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:02\n",
      "num of updates: 3500\n",
      "action loss: 0.12560\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16413\n",
      "lr 0.00035\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:03\n",
      "num of updates: 3600\n",
      "action loss: 0.12578\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13037\n",
      "lr 0.00036\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:04\n",
      "num of updates: 3700\n",
      "action loss: 0.12559\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19161\n",
      "lr 0.00037\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:05\n",
      "num of updates: 3800\n",
      "action loss: 0.12531\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20194\n",
      "lr 0.00038\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:06\n",
      "num of updates: 3900\n",
      "action loss: 0.12552\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14703\n",
      "lr 0.00039\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:07\n",
      "num of updates: 4000\n",
      "action loss: 0.12542\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14994\n",
      "lr 0.00040\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:08\n",
      "num of updates: 4100\n",
      "action loss: 0.12490\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15930\n",
      "lr 0.00041\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:09\n",
      "num of updates: 4200\n",
      "action loss: 0.12537\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13102\n",
      "lr 0.00042\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:10\n",
      "num of updates: 4300\n",
      "action loss: 0.12515\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16791\n",
      "lr 0.00043\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:11\n",
      "num of updates: 4400\n",
      "action loss: 0.12479\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15100\n",
      "lr 0.00044\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:12\n",
      "num of updates: 4500\n",
      "action loss: 0.12482\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17293\n",
      "lr 0.00045\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:13\n",
      "num of updates: 4600\n",
      "action loss: 0.12493\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19295\n",
      "lr 0.00046\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:13\n",
      "num of updates: 4700\n",
      "action loss: 0.12499\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20816\n",
      "lr 0.00047\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:14\n",
      "num of updates: 4800\n",
      "action loss: 0.12489\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.24106\n",
      "lr 0.00048\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:15\n",
      "num of updates: 4900\n",
      "action loss: 0.12511\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.24173\n",
      "lr 0.00049\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:16\n",
      "num of updates: 5000\n",
      "action loss: 0.12529\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12495\n",
      "lr 0.00050\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:17\n",
      "num of updates: 5100\n",
      "action loss: 0.12463\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13856\n",
      "lr 0.00051\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:18\n",
      "num of updates: 5200\n",
      "action loss: 0.12455\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11650\n",
      "lr 0.00052\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:19\n",
      "num of updates: 5300\n",
      "action loss: 0.12448\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15594\n",
      "lr 0.00053\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:20\n",
      "num of updates: 5400\n",
      "action loss: 0.12449\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19431\n",
      "lr 0.00054\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:22\n",
      "num of updates: 5500\n",
      "action loss: 0.12479\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17266\n",
      "lr 0.00055\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:22\n",
      "num of updates: 5600\n",
      "action loss: 0.12429\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17958\n",
      "lr 0.00056\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:23\n",
      "num of updates: 5700\n",
      "action loss: 0.12451\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19444\n",
      "lr 0.00057\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:24\n",
      "num of updates: 5800\n",
      "action loss: 0.12431\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.23564\n",
      "lr 0.00058\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:25\n",
      "num of updates: 5900\n",
      "action loss: 0.12506\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16611\n",
      "lr 0.00059\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:26\n",
      "num of updates: 6000\n",
      "action loss: 0.12442\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.21679\n",
      "lr 0.00060\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:27\n",
      "num of updates: 6100\n",
      "action loss: 0.12415\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.24492\n",
      "lr 0.00061\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:29\n",
      "num of updates: 6200\n",
      "action loss: 0.12444\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12948\n",
      "lr 0.00062\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:29\n",
      "num of updates: 6300\n",
      "action loss: 0.12423\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11264\n",
      "lr 0.00063\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:30\n",
      "num of updates: 6400\n",
      "action loss: 0.12416\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10230\n",
      "lr 0.00064\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:31\n",
      "num of updates: 6500\n",
      "action loss: 0.12430\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14368\n",
      "lr 0.00065\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:32\n",
      "num of updates: 6600\n",
      "action loss: 0.12412\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11747\n",
      "lr 0.00066\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:33\n",
      "num of updates: 6700\n",
      "action loss: 0.12402\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.23527\n",
      "lr 0.00067\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:34\n",
      "num of updates: 6800\n",
      "action loss: 0.12412\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16834\n",
      "lr 0.00068\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:35\n",
      "num of updates: 6900\n",
      "action loss: 0.12409\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15882\n",
      "lr 0.00069\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:36\n",
      "num of updates: 7000\n",
      "action loss: 0.12430\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09989\n",
      "lr 0.00070\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:37\n",
      "num of updates: 7100\n",
      "action loss: 0.12439\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14318\n",
      "lr 0.00071\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:38\n",
      "num of updates: 7200\n",
      "action loss: 0.12472\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.21030\n",
      "lr 0.00072\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:39\n",
      "num of updates: 7300\n",
      "action loss: 0.12550\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16199\n",
      "lr 0.00073\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:40\n",
      "num of updates: 7400\n",
      "action loss: 0.12423\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.22176\n",
      "lr 0.00074\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:41\n",
      "num of updates: 7500\n",
      "action loss: 0.12462\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.17965\n",
      "lr 0.00075\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:42\n",
      "num of updates: 7600\n",
      "action loss: 0.12422\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.20773\n",
      "lr 0.00076\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:43\n",
      "num of updates: 7700\n",
      "action loss: 0.12429\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18971\n",
      "lr 0.00077\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:44\n",
      "num of updates: 7800\n",
      "action loss: 0.12441\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15419\n",
      "lr 0.00078\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:45\n",
      "num of updates: 7900\n",
      "action loss: 0.12495\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16065\n",
      "lr 0.00079\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:46\n",
      "num of updates: 8000\n",
      "action loss: 0.12435\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15437\n",
      "lr 0.00080\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:47\n",
      "num of updates: 8100\n",
      "action loss: 0.12423\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12203\n",
      "lr 0.00081\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:48\n",
      "num of updates: 8200\n",
      "action loss: 0.12452\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16480\n",
      "lr 0.00082\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:49\n",
      "num of updates: 8300\n",
      "action loss: 0.12425\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.18424\n",
      "lr 0.00083\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:50\n",
      "num of updates: 8400\n",
      "action loss: 0.12414\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.19071\n",
      "lr 0.00084\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:51\n",
      "num of updates: 8500\n",
      "action loss: 0.12385\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08872\n",
      "lr 0.00085\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:52\n",
      "num of updates: 8600\n",
      "action loss: 0.12460\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07822\n",
      "lr 0.00086\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:53\n",
      "num of updates: 8700\n",
      "action loss: 0.12456\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16268\n",
      "lr 0.00087\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:54\n",
      "num of updates: 8800\n",
      "action loss: 0.12391\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11978\n",
      "lr 0.00088\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:55\n",
      "num of updates: 8900\n",
      "action loss: 0.12412\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16927\n",
      "lr 0.00089\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:55\n",
      "num of updates: 9000\n",
      "action loss: 0.12439\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14395\n",
      "lr 0.00090\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:56\n",
      "num of updates: 9100\n",
      "action loss: 0.12392\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13158\n",
      "lr 0.00091\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:57\n",
      "num of updates: 9200\n",
      "action loss: 0.12427\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16294\n",
      "lr 0.00092\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:58\n",
      "num of updates: 9300\n",
      "action loss: 0.12430\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12894\n",
      "lr 0.00093\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:59\n",
      "num of updates: 9400\n",
      "action loss: 0.12432\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12499\n",
      "lr 0.00094\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:00\n",
      "num of updates: 9500\n",
      "action loss: 0.12462\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09643\n",
      "lr 0.00095\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:01\n",
      "num of updates: 9600\n",
      "action loss: 0.12423\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12553\n",
      "lr 0.00096\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:02\n",
      "num of updates: 9700\n",
      "action loss: 0.12458\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13623\n",
      "lr 0.00097\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:03\n",
      "num of updates: 9800\n",
      "action loss: 0.12492\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.21604\n",
      "lr 0.00098\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:04\n",
      "num of updates: 9900\n",
      "action loss: 0.12417\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10387\n",
      "lr 0.00099\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:05\n",
      "num of updates: 10000\n",
      "action loss: 0.12379\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11815\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:06\n",
      "num of updates: 10100\n",
      "action loss: 0.12420\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08253\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:07\n",
      "num of updates: 10200\n",
      "action loss: 0.12417\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11515\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:08\n",
      "num of updates: 10300\n",
      "action loss: 0.12551\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.15036\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:09\n",
      "num of updates: 10400\n",
      "action loss: 0.12458\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04797\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:10\n",
      "num of updates: 10500\n",
      "action loss: 0.12613\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.21145\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:11\n",
      "num of updates: 10600\n",
      "action loss: 0.12500\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12922\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:12\n",
      "num of updates: 10700\n",
      "action loss: 0.12494\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16263\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:13\n",
      "num of updates: 10800\n",
      "action loss: 0.12532\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07011\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:14\n",
      "num of updates: 10900\n",
      "action loss: 0.12647\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14372\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:15\n",
      "num of updates: 11000\n",
      "action loss: 0.12546\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06841\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:16\n",
      "num of updates: 11100\n",
      "action loss: 0.12493\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14922\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:17\n",
      "num of updates: 11200\n",
      "action loss: 0.12414\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.16749\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:17\n",
      "num of updates: 11300\n",
      "action loss: 0.12443\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.12069\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:19\n",
      "num of updates: 11400\n",
      "action loss: 0.12425\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13465\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:20\n",
      "num of updates: 11500\n",
      "action loss: 0.12521\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13763\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:21\n",
      "num of updates: 11600\n",
      "action loss: 0.12488\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11989\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:22\n",
      "num of updates: 11700\n",
      "action loss: 0.12389\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09720\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:22\n",
      "num of updates: 11800\n",
      "action loss: 0.12428\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09708\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:23\n",
      "num of updates: 11900\n",
      "action loss: 0.12422\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04028\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:24\n",
      "num of updates: 12000\n",
      "action loss: 0.12490\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10480\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:25\n",
      "num of updates: 12100\n",
      "action loss: 0.12517\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08525\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:26\n",
      "num of updates: 12200\n",
      "action loss: 0.12463\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10586\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:28\n",
      "num of updates: 12300\n",
      "action loss: 0.12464\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.13449\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:28\n",
      "num of updates: 12400\n",
      "action loss: 0.12573\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.11686\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:29\n",
      "num of updates: 12500\n",
      "action loss: 0.12450\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06898\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:30\n",
      "num of updates: 12600\n",
      "action loss: 0.12426\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09310\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:31\n",
      "num of updates: 12700\n",
      "action loss: 0.12522\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10037\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:33\n",
      "num of updates: 12800\n",
      "action loss: 0.12419\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10868\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:34\n",
      "num of updates: 12900\n",
      "action loss: 0.12369\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07626\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:35\n",
      "num of updates: 13000\n",
      "action loss: 0.12394\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04535\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:35\n",
      "num of updates: 13100\n",
      "action loss: 0.12395\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08388\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:36\n",
      "num of updates: 13200\n",
      "action loss: 0.12404\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06718\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:38\n",
      "num of updates: 13300\n",
      "action loss: 0.12399\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06636\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:40\n",
      "num of updates: 13400\n",
      "action loss: 0.12363\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08091\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:41\n",
      "num of updates: 13500\n",
      "action loss: 0.12358\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06253\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:45\n",
      "num of updates: 13600\n",
      "action loss: 0.12448\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10766\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:49\n",
      "num of updates: 13700\n",
      "action loss: 0.12410\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07718\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:53\n",
      "num of updates: 13800\n",
      "action loss: 0.12373\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06558\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:58\n",
      "num of updates: 13900\n",
      "action loss: 0.12438\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09941\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:02\n",
      "num of updates: 14000\n",
      "action loss: 0.12509\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08753\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:07\n",
      "num of updates: 14100\n",
      "action loss: 0.12562\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10461\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:12\n",
      "num of updates: 14200\n",
      "action loss: 0.12469\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10484\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:16\n",
      "num of updates: 14300\n",
      "action loss: 0.12415\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08745\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:20\n",
      "num of updates: 14400\n",
      "action loss: 0.12543\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.10339\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:25\n",
      "num of updates: 14500\n",
      "action loss: 0.12441\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08552\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:29\n",
      "num of updates: 14600\n",
      "action loss: 0.12410\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09544\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:34\n",
      "num of updates: 14700\n",
      "action loss: 0.12384\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07161\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:38\n",
      "num of updates: 14800\n",
      "action loss: 0.12370\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08255\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:43\n",
      "num of updates: 14900\n",
      "action loss: 0.12377\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07251\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:47\n",
      "num of updates: 15000\n",
      "action loss: 0.12341\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06985\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:51\n",
      "num of updates: 15100\n",
      "action loss: 0.12388\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07375\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:56\n",
      "num of updates: 15200\n",
      "action loss: 0.12456\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03649\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:00\n",
      "num of updates: 15300\n",
      "action loss: 0.12409\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05101\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:05\n",
      "num of updates: 15400\n",
      "action loss: 0.12370\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06833\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:09\n",
      "num of updates: 15500\n",
      "action loss: 0.12412\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03505\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:14\n",
      "num of updates: 15600\n",
      "action loss: 0.12603\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06216\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:18\n",
      "num of updates: 15700\n",
      "action loss: 0.12454\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.14549\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:22\n",
      "num of updates: 15800\n",
      "action loss: 0.12483\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05883\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:27\n",
      "num of updates: 15900\n",
      "action loss: 0.12541\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05246\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:31\n",
      "num of updates: 16000\n",
      "action loss: 0.12439\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08953\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:35\n",
      "num of updates: 16100\n",
      "action loss: 0.12533\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05342\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:40\n",
      "num of updates: 16200\n",
      "action loss: 0.12384\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06402\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:44\n",
      "num of updates: 16300\n",
      "action loss: 0.12391\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05820\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:48\n",
      "num of updates: 16400\n",
      "action loss: 0.12412\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05772\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:52\n",
      "num of updates: 16500\n",
      "action loss: 0.12374\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.09023\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:57\n",
      "num of updates: 16600\n",
      "action loss: 0.12402\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05180\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:01\n",
      "num of updates: 16700\n",
      "action loss: 0.12379\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07361\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:05\n",
      "num of updates: 16800\n",
      "action loss: 0.12432\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.01614\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:09\n",
      "num of updates: 16900\n",
      "action loss: 0.12363\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07209\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:13\n",
      "num of updates: 17000\n",
      "action loss: 0.12525\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06483\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:18\n",
      "num of updates: 17100\n",
      "action loss: 0.12390\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.02569\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:22\n",
      "num of updates: 17200\n",
      "action loss: 0.12372\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06609\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:26\n",
      "num of updates: 17300\n",
      "action loss: 0.12395\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05484\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:30\n",
      "num of updates: 17400\n",
      "action loss: 0.12473\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06002\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:34\n",
      "num of updates: 17500\n",
      "action loss: 0.12367\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.07257\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:39\n",
      "num of updates: 17600\n",
      "action loss: 0.12375\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05295\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:43\n",
      "num of updates: 17700\n",
      "action loss: 0.12389\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03107\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:47\n",
      "num of updates: 17800\n",
      "action loss: 0.12377\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04158\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:51\n",
      "num of updates: 17900\n",
      "action loss: 0.12430\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.02850\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:56\n",
      "num of updates: 18000\n",
      "action loss: 0.12357\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05896\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:00\n",
      "num of updates: 18100\n",
      "action loss: 0.12366\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04733\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:04\n",
      "num of updates: 18200\n",
      "action loss: 0.12391\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.02811\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:08\n",
      "num of updates: 18300\n",
      "action loss: 0.12346\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.08076\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:13\n",
      "num of updates: 18400\n",
      "action loss: 0.12366\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04276\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:17\n",
      "num of updates: 18500\n",
      "action loss: 0.12361\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03291\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:21\n",
      "num of updates: 18600\n",
      "action loss: 0.12365\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04149\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:25\n",
      "num of updates: 18700\n",
      "action loss: 0.12467\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04715\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:29\n",
      "num of updates: 18800\n",
      "action loss: 0.12363\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04341\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:34\n",
      "num of updates: 18900\n",
      "action loss: 0.12484\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.06351\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:38\n",
      "num of updates: 19000\n",
      "action loss: 0.12419\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.01405\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:42\n",
      "num of updates: 19100\n",
      "action loss: 0.12423\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.02378\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:46\n",
      "num of updates: 19200\n",
      "action loss: 0.12361\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03206\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:51\n",
      "num of updates: 19300\n",
      "action loss: 0.12335\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03329\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:55\n",
      "num of updates: 19400\n",
      "action loss: 0.12403\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.05131\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:59\n",
      "num of updates: 19500\n",
      "action loss: 0.12390\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03986\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:03\n",
      "num of updates: 19600\n",
      "action loss: 0.12348\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.04676\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:08\n",
      "num of updates: 19700\n",
      "action loss: 0.12344\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.01294\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:12\n",
      "num of updates: 19800\n",
      "action loss: 0.12330\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03368\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:16\n",
      "num of updates: 19900\n",
      "action loss: 0.12326\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.03589\n",
      "lr 0.00100\n",
      "achieved average reward:  8.0\n",
      "saving max score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:20\n",
      "num of updates: 20000\n",
      "action loss: 0.12393\n",
      "eval avg reward: 8.00000\n",
      "best score: 8.00000\n",
      "eval_avg_ep_len 2.00000\n",
      "grad_norm 0.02032\n",
      "lr 0.00100\n",
      "============================================================\n",
      "finished training!\n",
      "============================================================\n",
      "started training at: 24-05-08-04-49-27\n",
      "finished training at: 24-05-08-04-56-47\n",
      "total training time: 0:07:20\n",
      "best score: 8.00000\n",
      "saved max d4rl score model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27_best.pt\n",
      "saved last updated model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/dt_runs/dt_random-walk_model_24-05-08-04-49-27.pt\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_csv.writer' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[122], line 93\u001B[0m\n\u001B[1;32m     81\u001B[0m \tresults \u001B[38;5;241m=\u001B[39m evaluate_on_env(model\u001B[38;5;241m=\u001B[39mmodel, traj_dataset\u001B[38;5;241m=\u001B[39mtraj_dataset,\n\u001B[1;32m     82\u001B[0m \t\t\t\t\t\t\t  device\u001B[38;5;241m=\u001B[39mdevice,context_len\u001B[38;5;241m=\u001B[39mcontext_len,\n\u001B[1;32m     83\u001B[0m \t\t\t\t\t\t\t  env\u001B[38;5;241m=\u001B[39menv, rtg_target\u001B[38;5;241m=\u001B[39mrtg_target,\n\u001B[1;32m     84\u001B[0m \t\t\t\t\t\t\t  num_eval_ep\u001B[38;5;241m=\u001B[39mnum_eval_ep, max_test_ep_len\u001B[38;5;241m=\u001B[39mmax_eval_ep_len)\n\u001B[1;32m     85\u001B[0m \tlogger\u001B[38;5;241m.\u001B[39mlog(model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m     86\u001B[0m \t\t\t   mean_action_loss\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mmean(log_action_losses),\n\u001B[1;32m     87\u001B[0m \t\t\t   eval_avg_reward\u001B[38;5;241m=\u001B[39mresults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meval/avg_reward\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     90\u001B[0m \t\t\t   lr\u001B[38;5;241m=\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mparam_groups[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     91\u001B[0m \t\t\t   important\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_norm\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m})\n\u001B[0;32m---> 93\u001B[0m \u001B[43mlogger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinish\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[121], line 61\u001B[0m, in \u001B[0;36mLogger.finish\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_started \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcsv_writer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclose\u001B[49m()\n",
      "\u001B[0;31mAttributeError\u001B[0m: '_csv.writer' object has no attribute 'close'"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:56:51.366055Z",
     "start_time": "2024-05-08T08:56:51.290550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = RandomWalkEnv(verbose=True)\n",
    "\n",
    "evaluate_on_env(\n",
    "\tmodel=model,\n",
    "\ttraj_dataset=traj_dataset,\n",
    "\tdevice=device,\n",
    "\tcontext_len=context_len,\n",
    "\tenv=env,\n",
    "\trtg_target=rtg_target,\n",
    "\tnum_eval_ep=num_eval_ep\n",
    ")"
   ],
   "id": "92e289508e2aea05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset. node: 0\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n",
      "reset. node: 0\n",
      "node: 0 action: 3\n",
      "node: 3 action: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval/avg_reward': 8.0, 'eval/avg_ep_len': 2.0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:59:12.360030Z",
     "start_time": "2024-05-08T08:59:10.614415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rtg_command = np.linspace(0, 20, 30)\n",
    "env = RandomWalkEnv()\n",
    "\n",
    "rtg_result = []\n",
    "\n",
    "for rtg in rtg_command:\n",
    "\tres = evaluate_on_env(\n",
    "\t\tmodel=model,\n",
    "\t\ttraj_dataset=traj_dataset,\n",
    "\t\tdevice=device,\n",
    "\t\tcontext_len=context_len,\n",
    "\t\tenv=env,\n",
    "\t\trtg_target=rtg,\n",
    "\t\tnum_eval_ep=num_eval_ep\n",
    "\t)\n",
    "\trtg_result.append(res['eval/avg_reward'])\n",
    "\n",
    "plt.plot(rtg_command, rtg_result, 'r')\n",
    "plt.plot(rtg_command, rtg_command, 'b')\n",
    "plt.legend([\"achieved\", \"commanded\"])\n",
    "plt.xlabel(\"rtg_command\")\n",
    "plt.ylabel(\"rtg_result\")"
   ],
   "id": "b9ce34c9dbc9916e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'rtg_result')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 127
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
