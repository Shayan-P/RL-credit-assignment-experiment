{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T10:45:45.516914Z",
     "start_time": "2024-05-12T10:45:45.399342Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from algorithms.random_policy import RandomPolicy\n",
    "from algorithms.sequence_models.decision_sequence_policy import DTPolicy\n",
    "from algorithms.sequence_models.decision_transformer.decision_transformer import DecisionTransformer\n",
    "from algorithms.sequence_models.evaluate import evaluate_on_env\n",
    "from data.door_key_dataset import DoorKeyDataset\n",
    "from data.random_walk_dataset import RandomWalkDataset\n",
    "from envs.door_key import DoorKeyEnv, DoorKeyEnvSmall\n",
    "from data.trajectory import LimitedContextWrapper\n",
    "from algorithms.sequence_models.config import TrainConfig\n",
    "from algorithms.sequence_models.decision_transformer.trainer import TrainerDT\n",
    "from envs.random_walk import RandomWalkEnv\n",
    "from experiment import Experiment\n",
    "import gymnasium as gym\n",
    "from functools import partial\n",
    "from algorithms.evaluate_policy import evaluate_policy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device is \", device)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T10:45:48.058854Z",
     "start_time": "2024-05-12T10:45:46.595934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from minigrid.wrappers import ImgObsWrapper\n",
    "\n",
    "inner_env = gym.make('MiniGrid-DoorKey-5x5-v0')\n",
    "inner_env_human = gym.make('MiniGrid-DoorKey-5x5-v0', render_mode='human')\n",
    "env = ImgObsWrapper(inner_env)\n",
    "env_human = ImgObsWrapper(inner_env_human)\n",
    "\n",
    "\n",
    "config = TrainConfig(max_eval_ep_len=env.max_steps, context_len=256,\n",
    "                     eval_model_interval=50)\n",
    "\n",
    "#################### todo\n",
    "# n_trajectories should be at least 10000 for the agent to learn I think \n",
    "####################\n",
    "# todo later also try running with higher n_trajectories\n",
    "n_trajectories = 10_000\n",
    "experiment_name = f\"experiment_door_key_dataset_size={n_trajectories}\"\n",
    "if DoorKeyDataset.exists(experiment_name):\n",
    "    traj_dataset = DoorKeyDataset.load(experiment_name)\n",
    "else:\n",
    "    traj_dataset = DoorKeyDataset(env, n_trajectories=n_trajectories, reward_scale=1, prob_keeping_nonzero=0.01)\n",
    "    traj_dataset.save(experiment_name)\n",
    "\n",
    "dt_model = DecisionTransformer(\n",
    "    state_dim=traj_dataset.state_dim(),\n",
    "    act_dim=traj_dataset.action_dim(),\n",
    "    n_blocks=config.n_blocks,\n",
    "    h_dim=config.embed_dim,\n",
    "    context_len=config.context_len,\n",
    "    n_heads=config.n_heads,\n",
    "    drop_p=config.dropout_p,\n",
    ").to(device)\n",
    "\n",
    "make_dt_policy = partial(DTPolicy, model=dt_model, traj_dataset=traj_dataset, device=device, max_test_ep_len=config.max_eval_ep_len, context_length=config.context_len)\n",
    "\n",
    "experiment = Experiment(\n",
    "    model_name='dt',\n",
    "    model=dt_model,\n",
    "    env_name='MiniGrid-DoorKey-5x5-v0',\n",
    "    env=env,\n",
    "    experiment_name='increase_context_size',\n",
    "    traj_dataset=traj_dataset,\n",
    "    dataset_name=f'size={len(traj_dataset)}',\n",
    "    config=config,\n",
    "    device=device,\n",
    "    eval_policies_and_names=[\n",
    "        (make_dt_policy(rtg=rtg), f'dt,rtg={rtg:.2f}')\n",
    "        for rtg in np.linspace(0, 1, 12)\n",
    "    ]\n",
    ")"
   ],
   "id": "5fa62e6934fa9a67",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T10:45:51.532132Z",
     "start_time": "2024-05-12T10:45:51.392937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rewards:\n",
    "plt.hist([traj.returns[0] for traj in traj_dataset], bins=50);"
   ],
   "id": "d6373adb8a43947a",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T10:46:00.815448Z",
     "start_time": "2024-05-12T10:45:54.226899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "report = experiment.train_for(600)\n",
    "experiment.save_fig(f\"_rtg_following_learning_process={experiment.custom_callback.iters}\")"
   ],
   "id": "19e0fa0a5c02d7b7",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "experiment.plot_loss(report)\n",
    "experiment.save_fig(f\"_loss_after={experiment.custom_callback.iters}\")"
   ],
   "id": "bc2c0a09d82a52b4",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# policy = RandomPolicy(env)\n",
    "policy = make_dt_policy(rtg=1)\n",
    "\n",
    "# you can also write another eval to store all the results not just the average\n",
    "evaluate_policy(policy, env, num_eval_ep=2)"
   ],
   "id": "4287c2ee0da95d04",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# wanna see what's happening? use env_human\n",
    "\n",
    "# you can also write another eval to store all the results not just the average\n",
    "evaluate_policy(policy, env_human, num_eval_ep=10)"
   ],
   "id": "c3656ecdd1212248",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "rtg_commands = np.linspace(0, 1.2, 10)\n",
    "rtg_results = [evaluate_policy(make_dt_policy(rtg=rtg), env, num_eval_ep=10)['eval/avg_reward']\n",
    "               for rtg in tqdm(rtg_commands)\n",
    "               ]\n",
    "max_in_dataset = max([traj.returns[0] for traj in traj_dataset])"
   ],
   "id": "670b89d7a8cf17ec",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(rtg_commands, rtg_results)\n",
    "plt.plot(rtg_commands, rtg_commands)\n",
    "plt.hlines(max_in_dataset, rtg_commands[0], rtg_commands[-1])\n",
    "plt.xlabel(\"rtg_command\")\n",
    "plt.xlabel(\"rtg_result\")\n",
    "plt.legend([\"agent\", \"x=y\", \"max in dataset\"])\n",
    "experiment.save_fig(f\"_rtg_following_iters={experiment.custom_callback.iters}\")"
   ],
   "id": "dcbe7b9974449e7",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "# todo the fancy graph with std and mean?",
   "id": "34b6b79b3324eac0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TODO: Maybe the context Length is small? Try increasing it!\n",
    "## TODO: Can we just not use a very large context length?!"
   ],
   "id": "dea69b3f998e7b4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now S4 model",
   "id": "26c84c9f064fb5be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T07:13:11.909553Z",
     "start_time": "2024-05-12T07:13:11.173468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from algorithms.sequence_models.decision_S4.dts4 import DecisionS4\n",
    "\n",
    "s4_model = DecisionS4(\n",
    "    state_dim=traj_dataset.state_dim(),\n",
    "    act_dim=traj_dataset.action_dim(),\n",
    "    h_dim=config.embed_dim,\n",
    "    drop_p=config.dropout_p,\n",
    ").to(device)\n",
    "\n",
    "make_s4_policy = partial(DTPolicy, model=s4_model, traj_dataset=traj_dataset, device=device, max_test_ep_len=config.max_eval_ep_len, context_length=config.context_len)\n",
    "\n",
    "experiment = Experiment(\n",
    "    model_name='s4',\n",
    "    model=s4_model,\n",
    "    env_name='MiniGrid-DoorKey-5x5-v0',\n",
    "    env=env,\n",
    "    experiment_name='increase_context_size',\n",
    "    traj_dataset=traj_dataset,\n",
    "    dataset_name=f'size={len(traj_dataset)}',\n",
    "    config=config,\n",
    "    device=device,\n",
    "    eval_policies_and_names=[\n",
    "        (make_s4_policy(rtg=rtg), f'dt,rtg={rtg:.2f}')\n",
    "        for rtg in np.linspace(0, 1, 12)\n",
    "    ]\n",
    ")"
   ],
   "id": "93398cb9d5949b2e",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:16:07.903794Z",
     "start_time": "2024-05-12T07:13:56.334214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "report = experiment.train_for(600)\n",
    "experiment.save_fig(f\"_rtg_following_learning_process={experiment.custom_callback.iters}\")"
   ],
   "id": "15ca6e7692af2df6",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:16:11.882456Z",
     "start_time": "2024-05-12T09:16:07.934774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment.plot_loss(report)\n",
    "experiment.save_fig(f\"_loss_after={experiment.custom_callback.iters}\")"
   ],
   "id": "62540ed1dfb1e5c1",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:45:38.871485Z",
     "start_time": "2024-05-12T09:45:28.263399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# policy = RandomPolicy(env)\n",
    "policy = make_s4_policy(rtg=1)\n",
    "\n",
    "# you can also write another eval to store all the results not just the average\n",
    "evaluate_policy(policy, env, num_eval_ep=30)"
   ],
   "id": "b28baa9c5f328c89",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:44:43.234481Z",
     "start_time": "2024-05-12T09:41:38.771249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# wanna see what's happening? use env_human\n",
    "\n",
    "# you can also write another eval to store all the results not just the average\n",
    "evaluate_policy(policy, env_human, num_eval_ep=10)"
   ],
   "id": "e43e68eb1b5e5802",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:46:28.126602Z",
     "start_time": "2024-05-12T09:45:55.165188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rtg_commands = np.linspace(0, 1.2, 10)\n",
    "rtg_results = [evaluate_policy(make_dt_policy(rtg=rtg), env, num_eval_ep=10)['eval/avg_reward']\n",
    "               for rtg in tqdm(rtg_commands)\n",
    "               ]\n",
    "max_in_dataset = max([traj.returns[0] for traj in traj_dataset])"
   ],
   "id": "cfa25bb1032dcd61",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:46:28.361577Z",
     "start_time": "2024-05-12T09:46:28.128634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(rtg_commands, rtg_results)\n",
    "plt.plot(rtg_commands, rtg_commands)\n",
    "plt.hlines(max_in_dataset, rtg_commands[0], rtg_commands[-1])\n",
    "plt.xlabel(\"rtg_command\")\n",
    "plt.xlabel(\"rtg_result\")\n",
    "plt.legend([\"agent\", \"x=y\", \"max in dataset\"])\n",
    "experiment.save_fig(f\"_rtg_following_iters={experiment.custom_callback.iters}\")"
   ],
   "id": "77e04bdf79981c90",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T09:46:45.335810Z",
     "start_time": "2024-05-12T09:46:45.302415Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "79e6129f319c07d9",
   "execution_count": 31,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
