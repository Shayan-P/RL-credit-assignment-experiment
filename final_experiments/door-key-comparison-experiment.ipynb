{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T11:01:24.504257Z",
     "start_time": "2024-05-12T11:01:24.428326Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from algorithms.sequence_models.config import TrainConfig\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device is \", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is  cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T11:01:32.997587Z",
     "start_time": "2024-05-12T11:01:26.105785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from minigrid.wrappers import ImgObsWrapper\n",
    "from algorithms.sequence_models.decision_S4.dts4 import DecisionS4\n",
    "from data.door_key_dataset import DoorKeyDataset\n",
    "from comparison_experiment import AutomatedComparisonExperiment\n",
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "inner_env = gym.make('MiniGrid-DoorKey-5x5-v0')\n",
    "inner_env_human = gym.make('MiniGrid-DoorKey-5x5-v0', render_mode='human')\n",
    "env = ImgObsWrapper(inner_env)\n",
    "env_human = ImgObsWrapper(inner_env_human)\n",
    "\n",
    "\n",
    "max_eval_ep_len = env.max_steps # todo change for other envs\n",
    "context_len = max_eval_ep_len + 2  # todo change for other envs (DECREASE TO IMPROVE SPEED)\n",
    "\n",
    "config = TrainConfig(max_eval_ep_len=max_eval_ep_len, context_len=max_eval_ep_len)\n",
    "\n",
    "n_trajectories = 10_000 # todo is this enough / too much?\n",
    "experiment_name = f\"experiment_door_key_dataset_size={n_trajectories}\"\n",
    "if DoorKeyDataset.exists(experiment_name):\n",
    "    traj_dataset = DoorKeyDataset.load(experiment_name)\n",
    "else:\n",
    "    reward_scale = 1 # todo change for other envs\n",
    "    traj_dataset = DoorKeyDataset(env, n_trajectories=n_trajectories, reward_scale=reward_scale, prob_keeping_nonzero=0.01)\n",
    "    traj_dataset.save(experiment_name)\n",
    "\n",
    "comparison_experiment = AutomatedComparisonExperiment(\n",
    "    env=env,\n",
    "    traj_dataset=traj_dataset,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    rtgs_for_train_eval=[0.3, 0.5, 0.7, 1], # todo change for other envs\n",
    "    rtgs_final_test=np.linspace(0, 1.1, 10, endpoint=True), # todo change for other envs\n",
    "    env_name=f\"MiniGrid-DoorKey-5x5-v0\", # todo change for other envs\n",
    "    experiment_name=\"automated_comparison\"\n",
    ")"
   ],
   "id": "746a64e1511b0dae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayan/projects/RL-credit-assignment-experiment/algorithms/sequence_models/decision_S4/s4.py:155: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"\n",
      "/home/shayan/miniconda3/envs/rl-explore/lib/python3.10/site-packages/lightning_fabric/plugins/environments/xla.py:18: DeprecationWarning: `ModuleAvailableCache` is a special case of `RequirementCache`. Please use `RequirementCache(module=...)` instead.\n",
      "  from lightning_fabric.accelerators.tpu import _XLA_AVAILABLE, TPUAccelerator\n",
      "/home/shayan/miniconda3/envs/rl-explore/lib/python3.10/site-packages/lightning_fabric/__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/shayan/miniconda3/envs/rl-explore/lib/python3.10/site-packages/pytorch_lightning/__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.\n",
      "/home/shayan/miniconda3/envs/rl-explore/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001B[33mWARN: env.max_steps to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.max_steps` for environment variables or `env.get_wrapper_attr('max_steps')` that will search the reminding wrappers.\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters 630811\n",
      "number of parameters 1159579\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T10:35:42.860991Z",
     "start_time": "2024-05-12T10:33:21.547374Z"
    }
   },
   "cell_type": "code",
   "source": "comparison_experiment.run_and_report(comparison_experiment.s4_experiment, 200)",
   "id": "377f7641c0aef462",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distribution of rewards in the dataset\n",
      "training started\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5bfce1d65664cd9b826820e6e9b161d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "time elapsed: 0:00:05\n",
      "num of updates: 100\n",
      "loss: 0.32132\n",
      "lr 0.00001\n",
      "grad_norm 0.19317\n",
      "============================================================\n",
      "time elapsed: 0:00:10\n",
      "num of updates: 200\n",
      "loss: 0.22560\n",
      "lr 0.00002\n",
      "grad_norm 0.09414\n",
      "============================================================\n",
      "time elapsed: 0:00:14\n",
      "num of updates: 300\n",
      "loss: 0.14831\n",
      "lr 0.00003\n",
      "grad_norm 0.02808\n",
      "============================================================\n",
      "time elapsed: 0:00:19\n",
      "num of updates: 400\n",
      "loss: 0.12943\n",
      "lr 0.00004\n",
      "grad_norm 0.02066\n",
      "============================================================\n",
      "time elapsed: 0:00:24\n",
      "num of updates: 500\n",
      "loss: 0.12514\n",
      "lr 0.00005\n",
      "grad_norm 0.01875\n",
      "============================================================\n",
      "time elapsed: 0:00:28\n",
      "num of updates: 600\n",
      "loss: 0.12221\n",
      "lr 0.00006\n",
      "grad_norm 0.01726\n",
      "============================================================\n",
      "time elapsed: 0:00:33\n",
      "num of updates: 700\n",
      "loss: 0.11982\n",
      "lr 0.00007\n",
      "grad_norm 0.01818\n",
      "============================================================\n",
      "time elapsed: 0:00:37\n",
      "num of updates: 800\n",
      "loss: 0.11727\n",
      "lr 0.00008\n",
      "grad_norm 0.01389\n",
      "============================================================\n",
      "time elapsed: 0:00:42\n",
      "num of updates: 900\n",
      "loss: 0.11355\n",
      "lr 0.00009\n",
      "grad_norm 0.01033\n",
      "============================================================\n",
      "time elapsed: 0:00:47\n",
      "num of updates: 1000\n",
      "loss: 0.10724\n",
      "lr 0.00010\n",
      "grad_norm 0.00985\n",
      "============================================================\n",
      "time elapsed: 0:00:51\n",
      "num of updates: 1100\n",
      "loss: 0.09786\n",
      "lr 0.00011\n",
      "grad_norm 0.01170\n",
      "============================================================\n",
      "time elapsed: 0:00:56\n",
      "num of updates: 1200\n",
      "loss: 0.08581\n",
      "lr 0.00012\n",
      "grad_norm 0.01355\n",
      "============================================================\n",
      "time elapsed: 0:01:00\n",
      "num of updates: 1300\n",
      "loss: 0.07182\n",
      "lr 0.00013\n",
      "grad_norm 0.01575\n",
      "============================================================\n",
      "time elapsed: 0:01:05\n",
      "num of updates: 1400\n",
      "loss: 0.05741\n",
      "lr 0.00014\n",
      "grad_norm 0.01816\n",
      "============================================================\n",
      "time elapsed: 0:01:09\n",
      "num of updates: 1500\n",
      "loss: 0.04458\n",
      "lr 0.00015\n",
      "grad_norm 0.01979\n",
      "============================================================\n",
      "time elapsed: 0:01:14\n",
      "num of updates: 1600\n",
      "loss: 0.03428\n",
      "lr 0.00016\n",
      "grad_norm 0.02855\n",
      "============================================================\n",
      "time elapsed: 0:01:18\n",
      "num of updates: 1700\n",
      "loss: 0.02658\n",
      "lr 0.00017\n",
      "grad_norm 0.02252\n",
      "============================================================\n",
      "time elapsed: 0:01:23\n",
      "num of updates: 1800\n",
      "loss: 0.02097\n",
      "lr 0.00018\n",
      "grad_norm 0.02374\n",
      "============================================================\n",
      "time elapsed: 0:01:27\n",
      "num of updates: 1900\n",
      "loss: 0.01682\n",
      "lr 0.00019\n",
      "grad_norm 0.01923\n",
      "============================================================\n",
      "time elapsed: 0:01:32\n",
      "num of updates: 2000\n",
      "loss: 0.01364\n",
      "lr 0.00020\n",
      "grad_norm 0.01811\n",
      "============================================================\n",
      "time elapsed: 0:01:37\n",
      "num of updates: 2100\n",
      "loss: 0.01125\n",
      "lr 0.00021\n",
      "grad_norm 0.01830\n",
      "============================================================\n",
      "time elapsed: 0:01:41\n",
      "num of updates: 2200\n",
      "loss: 0.00926\n",
      "lr 0.00022\n",
      "grad_norm 0.01682\n",
      "============================================================\n",
      "time elapsed: 0:01:46\n",
      "num of updates: 2300\n",
      "loss: 0.00765\n",
      "lr 0.00023\n",
      "grad_norm 0.01691\n",
      "============================================================\n",
      "time elapsed: 0:01:50\n",
      "num of updates: 2400\n",
      "loss: 0.00633\n",
      "lr 0.00024\n",
      "grad_norm 0.01305\n",
      "============================================================\n",
      "time elapsed: 0:01:55\n",
      "num of updates: 2500\n",
      "loss: 0.00522\n",
      "lr 0.00025\n",
      "grad_norm 0.01501\n",
      "============================================================\n",
      "time elapsed: 0:02:00\n",
      "num of updates: 2600\n",
      "loss: 0.00433\n",
      "lr 0.00026\n",
      "grad_norm 0.01238\n",
      "============================================================\n",
      "time elapsed: 0:02:04\n",
      "num of updates: 2700\n",
      "loss: 0.00359\n",
      "lr 0.00027\n",
      "grad_norm 0.00915\n",
      "============================================================\n",
      "time elapsed: 0:02:09\n",
      "num of updates: 2800\n",
      "loss: 0.00297\n",
      "lr 0.00028\n",
      "grad_norm 0.00969\n",
      "============================================================\n",
      "time elapsed: 0:02:13\n",
      "num of updates: 2900\n",
      "loss: 0.00247\n",
      "lr 0.00029\n",
      "grad_norm 0.00961\n",
      "============================================================\n",
      "time elapsed: 0:02:18\n",
      "num of updates: 3000\n",
      "loss: 0.00206\n",
      "lr 0.00030\n",
      "grad_norm 0.00729\n",
      "saving current model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/MiniGrid-DoorKey-5x5-v0/dt/automated_comparison/automated_comparison_size=23_model_model_24-05-12-06-33-00.pt\n",
      "saving checkpoint model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/MiniGrid-DoorKey-5x5-v0/dt/automated_comparison/automated_comparison_size=23_model24-05-12-06-33-00checkpoint__30.pt\n",
      "saving best model at: /home/shayan/projects/RL-credit-assignment-experiment/logs/MiniGrid-DoorKey-5x5-v0/dt/automated_comparison/automated_comparison_size=23_model_model_24-05-12-06-33-00_best.pt\n",
      "evaluating the model: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcomparison_experiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_and_report\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcomparison_experiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ms4_experiment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/final_experiments/comparison_experiment.py:99\u001B[0m, in \u001B[0;36mAutomatedComparisonExperiment.run_and_report\u001B[0;34m(self, experiment, epochs)\u001B[0m\n\u001B[1;32m     96\u001B[0m experiment\u001B[38;5;241m.\u001B[39msave_fig(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdistribution_of_returns_in_trajectories\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     98\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[0;32m---> 99\u001B[0m report \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdt_experiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_for\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    100\u001B[0m experiment\u001B[38;5;241m.\u001B[39msave_fig(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_rtg_following_learning_process=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexperiment\u001B[38;5;241m.\u001B[39mcustom_callback\u001B[38;5;241m.\u001B[39miters\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    102\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/final_experiments/experiment.py:126\u001B[0m, in \u001B[0;36mExperiment.train_for\u001B[0;34m(self, epochs)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_for\u001B[39m(\u001B[38;5;28mself\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 126\u001B[0m     report \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconcat_report \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconcat_report, report])\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m report\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/algorithms/sequence_models/trainer.py:60\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, epochs)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# for callback in self.callbacks:\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m#     callback(df=df_iter, model=self.model, iterations)\u001B[39;00m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m---> 60\u001B[0m     \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m df_iter[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain/iteration\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m i_train_iter\n\u001B[1;32m     62\u001B[0m df\u001B[38;5;241m.\u001B[39mappend(df_iter)\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/final_experiments/callbacks.py:122\u001B[0m, in \u001B[0;36mLogSaveModelEvaluateCallback.epoch\u001B[0;34m(self, model, report)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog(loss\u001B[38;5;241m=\u001B[39mloss, lr\u001B[38;5;241m=\u001B[39mlr, grad_norm\u001B[38;5;241m=\u001B[39mgrad_norm)\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_model(loss\u001B[38;5;241m=\u001B[39mloss, model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m--> 122\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpbar\u001B[38;5;241m.\u001B[39mset_description(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLoss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBest_Model_Loss=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_best_model_saved\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGrad_norm \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrad_norm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    129\u001B[0m ]))\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/final_experiments/callbacks.py:95\u001B[0m, in \u001B[0;36mLogSaveModelEvaluateCallback.log_eval\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mevaluating the model: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m policy, name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicies_and_names:\n\u001B[0;32m---> 95\u001B[0m     report \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_policy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_eval_ep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_eval_ep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_test_ep_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_eval_ep_len\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     report[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_iter\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miters\n\u001B[1;32m     97\u001B[0m     report[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpolicy\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m name\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/algorithms/evaluate_policy.py:19\u001B[0m, in \u001B[0;36mevaluate_policy\u001B[0;34m(policy, env, num_eval_ep, max_test_ep_len, render)\u001B[0m\n\u001B[1;32m     16\u001B[0m policy\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_test_ep_len):\n\u001B[0;32m---> 19\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43mpolicy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     obs, reward, terminated, truncated, _ \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[1;32m     21\u001B[0m     done \u001B[38;5;241m=\u001B[39m terminated \u001B[38;5;129;01mor\u001B[39;00m truncated\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/algorithms/sequence_models/decision_sequence_policy.py:89\u001B[0m, in \u001B[0;36mDTPolicy.predict\u001B[0;34m(self, obs)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrewards_to_go[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mt] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_rtg\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mt \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext_length:\n\u001B[0;32m---> 89\u001B[0m     _, act_preds, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimesteps\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext_length\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m                                         \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstates\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext_length\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m                                         \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactions\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext_length\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m                                         \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrewards_to_go\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext_length\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     act \u001B[38;5;241m=\u001B[39m act_preds[\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mt]\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/projects/RL-credit-assignment-experiment/algorithms/sequence_models/decision_transformer/decision_transformer.py:131\u001B[0m, in \u001B[0;36mDecisionTransformer.forward\u001B[0;34m(self, timesteps, states, actions, returns_to_go)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, timesteps, states, actions, returns_to_go):\n\u001B[1;32m    129\u001B[0m     B, T, _ \u001B[38;5;241m=\u001B[39m states\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m--> 131\u001B[0m     time_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_timestep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimesteps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;66;03m# time embeddings are treated similar to positional embeddings\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     state_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_state(states) \u001B[38;5;241m+\u001B[39m time_embeddings\n",
      "File \u001B[0;32m~/miniconda3/envs/rl-explore/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl-explore/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl-explore/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl-explore/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001B[0m, in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2258\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[1;32m   2259\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[1;32m   2260\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[1;32m   2261\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[1;32m   2262\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[1;32m   2263\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[0;32m-> 2264\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "comparison_experiment.run_and_report(comparison_experiment.dt_experiment, 200)",
   "id": "c847859f92de48de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T11:02:17.468558Z",
     "start_time": "2024-05-12T11:01:50.792432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# see and record\n",
    "from algorithms.evaluate_policy import evaluate_policy\n",
    "\n",
    "policy = comparison_experiment.make_dt_policy(rtg=1)\n",
    "evaluate_policy(policy, env_human, num_eval_ep=1)"
   ],
   "id": "ee8dd112b218668a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval/avg_reward': 0.0, 'eval/avg_ep_len': 250.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# see and record\n",
    "from algorithms.evaluate_policy import evaluate_policy\n",
    "\n",
    "policy = comparison_experiment.make_s4_policy(rtg=1)\n",
    "evaluate_policy(policy, env_human, num_eval_ep=1)"
   ],
   "id": "d2ab3c0fd9c56b09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
